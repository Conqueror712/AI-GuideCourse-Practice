{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9ded31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 基于Pytorch构建简单的三层分类神经网络\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Pytorch下采用Adam梯度下降法进行神经网络的权值更新\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m使用库构建简单的二分类数据集，编写简单的三层分类神经网络，\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m输入和输出均有两个神经元，中间隐藏层可设置 N 个神经元，\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m学习梯度计算，及梯度下降法进行神经网络的权值修改。\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 基于Pytorch构建简单的三层分类神经网络\n",
    "\n",
    "# Pytorch下采用Adam梯度下降法进行神经网络的权值更新\n",
    "\n",
    "'''\n",
    "使用库构建简单的二分类数据集，编写简单的三层分类神经网络，\n",
    "输入和输出均有两个神经元，中间隐藏层可设置 N 个神经元，\n",
    "采用 Relu 函数作为激活函数。\n",
    "数据集按两个类构建，每个类的样本为两维，分散在类中心附近。\n",
    "学习梯度计算，及梯度下降法进行神经网络的权值修改。\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch.manual_seed(1)  # reproducible\n",
    "\n",
    "# make fake data\n",
    "\n",
    "n_data = torch.ones(100, 2)\n",
    "x0 = torch.normal(2 * n_data, 1)  # class0 x data (tensor), shape=(100, 2)\n",
    "y0 = torch.zeros(100)  # class0 y data (tensor), shape=(100, 1)\n",
    "x1 = torch.normal(-2 * n_data, 1)  # class1 x data (tensor), shape=(100, 2)\n",
    "y1 = torch.ones(100)  # class1 y data (tensor), shape=(100, 1)\n",
    "x = torch.cat((x0, x1), 0).type(torch.FloatTensor)  # shape (200, 2) FloatTensor = 32-bit floating\n",
    "y = torch.cat((y0, y1), ).type(torch.LongTensor)  # shape (200,) LongTensor = 64-bit integer\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # hidden layer\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)  # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.hidden(x))  # activation function for hidden layer\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(n_feature=2, n_hidden=10, n_output=2)  # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "plt.ion()  # something about\n",
    "\n",
    "for t in range(100):\n",
    "    out = net(x)  # input x and predict based on x\n",
    "    loss = loss_func(out, y)  # must be (1. nn output, 2. target), the target label is NOTone-hotted\n",
    "    optimizer.zero_grad()  # clear gradients for next train\n",
    "    loss.backward()  # backpropagation, compute gradients\n",
    "    optimizer.step()  # apply gradients\n",
    "    if t % 2 == 0:  # plot and show learning process\n",
    "        plt.cla()\n",
    "        prediction = torch.max(out, 1)[1]\n",
    "        pred_y = prediction.data.numpy()\n",
    "        target_y = y.data.numpy()\n",
    "        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn')\n",
    "        accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n",
    "        plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color': 'red'})\n",
    "        plt.pause(0.1)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
